# Predicting-Fine-Art-Photography-The-Role-of-Depth-and-Contrast

#### Abstract
In this project, we aim to predict fine art photography by using the depth of the photographs. There is a widespread belief in contemporary art theories that the reason why artistic photography is impressive is the perception of depth it creates. It is believed that this specific perception is kind of technic that creates the beauty in fine art photography. The perception of the depth can be described by parameters such as contrast and sharpness. At this initial step, we just started with the contrast of the photographs and tried to improve our prediction algorithm. Unfortunately, the results are not as good as expected.

#### Aim
The main objective of the project is to illuminate the cultural, societal, psychological, and cognitive factors that shape our perception of fine art and normal photographs. To fulfill this task, we should formalize the factors that affect our perception of fine art photography. As mentioned above, the perception of depth is considered to be the thing that most affect our perception of fine art photography. In order to analyze deeply the perception of depth, we should be able to formalize it with objective parameters. The parameters such as contrast and sharpness were initially chosen to categorize the fine art photographs. However, at this initial step, we only use the contrast to see if we can get successful outcomes. As the art theories support, contrast is supposed to strengthen our perception of the depth. Thus, another main task is to improve the classification and prediction power of our algorithm by using contrast values. We make tests by using three different datasets and two different neural network models. The datasets consist of the dataset that involves general contrast values of the photographs, the dataset that involves regional contrast values of the photographs, and the standard dataset which involves the data from all channels. We basically compare the outcomes of these datasets and the neural network algorithms that are used in classification and prediction.

#### Method
As it is mentioned, we divide the task into three main parts. In the first part, we classify and predict the photographs by using a standard convolutional neural network (CNN) model. The first step, namely the Photography Dataset, is taken as an initial case which will be compared with the other two cases. Through this comparisons, we are planning to make inference about whether the contrast has a measurable impact on our perception of depth and fine art photography. The other datasets are Contrast Dataset and Regional Contrast Dataset. If Contrast Dataset and Regional Contrast Dataset give us better outcomes in terms of prediction accuracies, then we may reach the conclusion that the perception of depth, which can be measured by contrast, have a measurable effect on our perception of fine art photographs.

#### Photography Dataset
This dataset is used to make a standard prediction by using standard technics and methods as it will be used make comparison with two other datasets, namely Contrast Dataset and Regional Contrast Dataset. The first thing to do is to create a new dataset by mixing two datasets: Magnum Photos Dataset for fine art photography and The Met Dataset for normal photographs. We choose 200 photographs from both datasets and create a new dataset named "photography" which consists of 400 photographs. After that, we need to reshape the image size. Since the most common shape among the new dataset is 400x600, we set the shape of the photographs as 400x600. In short, the root directory is named as "resized_mix". After that, we create a csv file based on our root directory "resized_mix" and we name it "photography.csv". To connect our root directory with the csv file, we define a Photography Dataset class. Photography Dataset class assures that the classification and prediction stages will be implemented accordingly. We split the train and test data by concerning the standards, 300 for training and 114 for testing, that is, 72% for training and 28% for testing. We define our CNN model to be compatible with 400x600 sized photographs. In this first step, we create two convolutional layers. We train based on the training set and test the data based on the test set. Finally, we plotted the losses and accuracies of our model based on our test set.

#### Contrast Dataset
The main difference between Contrast Dataset and Photography Dataset is that we use general contrast values of the photographs in Contrast Dataset. The general contrast values are collected via gray level co-occurrence matrices (GLCM). GLCM properties is a very common method in texture analyze. In object detection, it may provide reliable outcomes and high accuracies based on its parameters. GLCM matrices provides different parameters yet we will only use the contrast. If we use contrast, it gives a 1x4 matrix for each photograph’s contrast value. That is, the contrast value of a photograph is represented by these 1x4 matrices. We define a function that finds the contrast matrices of photographs. Since the contrast matrices are one dimensional matrices, the prediction algorithm is designed to be implanted by means of a csv file. In this part, instead of the collocation of the root directory and the csv file, we use a csv file and a feed forward neural network in prediction. Thus, Contrast Dataset only refers to the csv file. Since the models such as perceptron, logistic regression, decision tree, random forest, etc. could not give better results, we choose to proceed with neural network. We use “BCEWithLogitsLoss” as the loss function and “Adam” as the optimizer because we get better results with the specific loss function and optimizer.

#### Regional Contrast Dataset
There are two main difference between Contrast Dataset and Regional Contrast Dataset. Firstly, while we use general contrast values of the photographs in Contrast Dataset, the other dataset includes regional contrast values of each photographs. That is to say, we get a 15x10 matrix to represent the contrast value of a photograph. The other important difference between these two datasets is that we use standard deviation method to calculate the contact values. In order to create the 15x10 matrices, we define a function named “analyze_regions” that calculates the contrast values of specific group of pixels. This time, we create a dataset class which resembles the Photography dataset, but the difference is that the class only takes the information of the photographs as 15x10 matrices of contrast values. That is, the function “analyze_regions” is inside the dataset class. Another thing is that we use convolutional neural network to better classify the two dimensional contrast values. We use CrossEntrpyLoss as our Loss function and ASGD as optimizer.

#### Results
We get the average accuracy of 64.76% and average loss of 0.48% from the first dataset. From the Contrast dataset, we get the average accuracy of 50.14% and average loss of 0.66%. Lastly, from the Regional Contrast Dataset, we get the average accuracy of 58.33% and average loss of 0.69%. The accuracy and loss values per epoch can be seen in the graphs below.

#### Conclusion
The results are obviously do not meet our expectations. There are several reasons for this. Firstly and most importantly, we work on a small dataset consisted of 414 photographs which diminish the prediction power of the three different algorithms. If we take our first dataset case, Photography Dataset, the accuracy score over 60% can be considered as a good starting point. This means that there is a measurable difference between fine art photography and normal photographs. However, neither the second dataset nor the last one give better accuracy and loss scores than the first one. The second reason for disappointing results is that by taking contrast values as smaller matrices such as 1x4 and 15x10 we collect less data for our prediction algorithm. That is, in the second and the third case, there are less data to process. One should not expect an algorithm get successful results based on very few data. This is partly because our photographs have lower image quality. That is, thirdly, our photographs have the lower image quality, and the low quality decreases the contrast information that we get from photographs. However, the regional contrast dataset are promising and open to improvement, since there is a considerable difference between the accuracy score of the Contrast Dataset and Regional Contrast Dataset.

#### References:
Carter, D., Some Important Principles of Photography. pp. 2. Booklet #3, The Northern Virginia Alliance of Camera Clubs, 2009

Horng, M. H., Texture Feature Coding Method for Texture Analysis and It’s Application. Journal of Optical Engineering, 42 ,1, pp. 228-238. 2003

Moulden, B., Kingdom F., Gatlet, L. F., The Standard Deviation of Luminance as a Metric for Contrast in Random-Dot Images. Perception, vol. 19, pp. 79-101. February, 1990

Riyadi, T., Setiawan, P. A., Visual Depth of Landscape Photography into Digital Illustration, pp. 188. In Proceedings of the 3rd International Conference on Social Sciences, Laws, Arts and Humanities, 2022

Weber, E. A., Vision Composition and Photography. pp. 56. Walter de Gruyter, Berlin, New York, 1980
